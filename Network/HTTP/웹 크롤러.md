웹 로봇 : 스스로 움직이는 사용자 에이전트. 사용자와 상호작용없이 자동으로 연속적인 웹 트랜잭션을 수행하는 소프트웨어. 크롤러라고도 불린다.

하나의 웹페이지로부터 그와 연결된 모든 웹페이지를 불러들여 재귀적으로 순회하는 로봇이다. 이렇게 쌓인 문서들은 검색 가능한 데이터베이스로 만들어져 특정 단어를 사용자가 입력하면 검색 가능하게 만들어진다.

크롤러는 URL 초기 집합인 루트 집합에서부터 시작한다. 시작 지점에서부터 계속해서 연결된 문서들을 수집하는 크롤러의 특성을 반영하면, 최대한 인기가 많은 사이트들(많은 문서를 담고 있는)을 루트 집합을 선정해야한다. 최대한 다양하고 많은 문서를 수집해야하므로 단순 인기가 많은 사이트들뿐만 아니라, 새로 생성된 페이지들이나 잘 쓰이지 않는 고립된 페이지들도 포함한다. 이러한 루트 집합은 시간이 지나면서 성장하여 새로운 크롤링을 위한 시드가 된다.

크롤링을 할 때 주의해야 할 점은 루프에 빠지지 않아야 한다는 것이다. 루트 집합에서 시작해서 마지막에 루트 집합으로 빠지면 크롤러가 갇히기 때문이다. 또한 같은 페이지를 반복해서 가져오는 것은 성능에 좋지 않다. 그렇기 때문에 루프를 피하려면 어디를 방문해야하는지 알아야 한다. 이를 위한 자료구조로 트리, 헤시 테이블, 비트맵 등을 사용한다.

웹 로봇(크롤러)를 가장 광범위하게 사용하는 것이 바로 인터넷 검색엔진이다. 검색엔진은 어떤 문서에 어떤 단어들이 존재하는지에 대한 색인을 생성할 수 있게 한다.

현대 검색엔진의 구조

    현대 검색엔진은 전 세계 웹 페이지들에 대한 'full-text index'라는 복잡합 로컬 데이터베이스를 생성한다. 검색엔진의 크롤러들은 웹페이지들을 수집하여 이 데이터베이스에 추가한다. 동시에 사용자들이 검색엔진, 그러니까 웹 검색 게이트웨이에 접근하면 게이트웨이는 크롤러들이 만들어놓은 데이터베이스에서 데이터를 검색하여 반환하게 된다.

    ![img](https://www.google.com/url?sa=i&url=https%3A%2F%2Fvelog.io%2F%40milk717%2FHTTP-%25EC%2599%2584%25EB%25B2%25BD-%25EA%25B0%2580%25EC%259D%25B4%25EB%2593%259C-9%25EC%259E%25A5-%25EC%259B%25B9-%25EB%25A1%259C%25EB%25B4%2587&psig=AOvVaw0TMbiuk-z0AvrbizxwVM2B&ust=1736927455659000&source=images&cd=vfe&opi=89978449&ved=0CBQQjRxqFwoTCNj015Hd9IoDFQAAAAAdAAAAABAE)
    